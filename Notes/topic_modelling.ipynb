{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic-modelling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingus-t/SPAI/blob/master/Notes/topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HforwMzklhI3",
        "colab_type": "text"
      },
      "source": [
        "# Topic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9F6HyCoL8w",
        "colab_type": "text"
      },
      "source": [
        "Trying to implement very basic topic modeling on a very small and simple dataset  \n",
        "\n",
        "- Method 1:   https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21    \n",
        "This is a copy/paste right now.\n",
        "ToDo: remove usernames and greetings (hi, hello)  \n",
        "data visualization (clustering?)\n",
        "\n",
        "- Method 2:  \n",
        "- Method 3:   \n",
        "\n",
        "Additional resources:  \n",
        "- http://liuyi-hu.github.io/projects/TopicModeling.pdf  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN4OwOOUvF7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIfaYKmamp_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading data from json file. \n",
        "\n",
        "#with open('transcript.js') as json_file:\n",
        "#    data1 = json.load(json_file)\n",
        "\n",
        "#data2 = json.loads(\"transcript.js\")\n",
        "\n",
        "pd.read_json(json.dumps(arr)).to_csv('transcript.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTnV28amo09T",
        "colab_type": "text"
      },
      "source": [
        "# Method #1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smyywhQWlf2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from   spacy.lang.en import English\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from   nltk.corpus import wordnet as wn\n",
        "from   nltk.stem.wordnet import WordNetLemmatizer\n",
        "import random\n",
        "import gensim\n",
        "from   gensim import corpora\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU-DiqEmr6CI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean text, return a list of tokens\n",
        "\n",
        "spacy.load('en')\n",
        "parser = English()\n",
        "def tokenize(text):\n",
        "    lda_tokens = []\n",
        "    tokens = parser(text)\n",
        "    for token in tokens:\n",
        "        if token.orth_.isspace():\n",
        "            continue\n",
        "        elif token.like_url:\n",
        "            lda_tokens.append('URL')\n",
        "        elif token.orth_.startswith('@'):\n",
        "            lda_tokens.append('SCREEN_NAME')\n",
        "        else:\n",
        "            lda_tokens.append(token.lower_)\n",
        "    return lda_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvssm6uzlxws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use NLTKâ€™s Wordnet to find the meanings of words, synonyms, antonyms, and more\n",
        "# use WordNetLemmatizer to get the root word\n",
        "\n",
        "nltk.download('wordnet')\n",
        "def get_lemma(word):\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "        return lemma\n",
        "def get_lemma2(word):\n",
        "    return WordNetLemmatizer().lemmatize(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSRP2KL0l0Zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29d8da9d-7a34-4322-bc07-cfe80770f082"
      },
      "source": [
        "# Filter out stop words\n",
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAPIMe1Vl2R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the text for topic modeling\n",
        "def prepare_text_for_lda(text):\n",
        "    tokens = tokenize(text)\n",
        "    tokens = [token for token in tokens if len(token) > 4]\n",
        "    tokens = [token for token in tokens if token not in en_stop]\n",
        "    tokens = [get_lemma(token) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-GSsym-voCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "cd933021-5464-4686-84dd-18a36e625bff"
      },
      "source": [
        "# see the convertation process\n",
        "# display ~1% of the data for assessment\n",
        "\n",
        "text_data = []\n",
        "with open('transcript.csv') as f:\n",
        "    for line in f:\n",
        "        tokens = prepare_text_for_lda(line)\n",
        "        if random.random() > .99:\n",
        "            print(tokens)\n",
        "            text_data.append(tokens)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['7,aftab', 'hasan', 'participate', 'multiple', 'project', 'showcase']\n",
            "['139,no', 'kaggle', 'competition', 'project', 'manditory', 'qualify', 'nanodegree']\n",
            "['356,\"1', 'obviously', 'virutal', 'meetup', 'check', 'announcement', 'channel', 'given', 'monday', 'completely', 'optional', 'savani', 'study', 'group', 'local', 'meetup', 'project', 'anyone', 'locality', 'country', 'study', 'group', 'working', 'project', 'share', 'interest', 'organizer', 'study', 'group', 'special', 'badge', 'another', 'channel', 'moderator', 'organizer', 'weekly', 'update', 'regard', 'study', 'group', 'direct', 'message', 'sg_project', 'shirt', 'mandatory', 'participate', 'optional', 'study', 'group']\n",
            "['419,yes', 'absolutely', 'daily', 'update', 'result', 'evaluation', 'point', 'matter', 'whether', 'complete', 'challenge', 'still', 'encourage', 'somebody', 'channel', '60daysofudacity', 'remain']\n",
            "['436,they', 'still', 'evaluation', 'point', 'daily', 'update', 'vamsi', 'worry', 'people', 'start', '60daysofudacity', 'challenge', 'since', 'enough', 'finish', 'challenge', 'right', 'count', 'somewhere', 'happen']\n",
            "['456,\"not', 'inactive', 'number', 'remember', 'peer', 'really', 'active', 'might', 'ahead', 'active', 'limit', 'inactive', 'slack', 'project', 'devote', 'entire', 'week']\n",
            "['590,\"wow', 'think', 'answer', 'question', 'pretty', 'detail', 'manner', 'smile', 'official', 'facebook', 'count', 'since', '60daysofudacity', 'evaluation', 'believe', 'slightly_smiling_face', 'official', 'initiatives*.', 'first', '60daysofudacity', 'another', 'study', 'group', 'heart', 'sorry', 'realise', 'classmate', 'already', 'answer', 'sweat_smile', 'search', 'meetups', '2.are', 'count', '60daysofudacity', 'challenge', 'factor', 'evaluation', 'require', 'meetup', 'reach', 'mutual', 'goal/', 'conclusion', 'fruitful', 'discussion', 'since', 'check', 'meetup', 'option', 'google', 'community', 'initiative', 'please', 'something', '60daysofudacity', 'relate', 'count', 'miss', 'sorry', 'posting', 'still', 'need', 'clarity', 'regard', 'thanks', 'heart', 'udacity', 'akshit', 'pikachu_amaze']\n",
            "['624,\"hi', 'mercian', 'really', 'sorry', 'initiative', 'completely', 'optional', 'add', 'challenge', 'update', 'conduct', 'virtual', 'meetupsa', 'picture', 'count', 'smile', 'hello', 'question', 'moderator', 'initiative', 'challenge', 'engagement', 'activity', 'writing', 'slack', 'creation', 'write', 'update', 'challenge', 'unable', 'attend', 'physical', 'meetup', 'around', 'meetup']\n",
            "['718,hi', 'adinugroho', 'certainly', 'change', 'continue', 'earlier', 'change', 'activity', '60days', 'challenge', 'later', 'choose', 'coding', 'practice', 'later', 'manage', 'group', 'project', 'count', 'afraid', 'choose', 'later', 'fulfill']\n",
            "['941,\"you', 'actually', 'activity', 'record', 'track', 'spend', 'slack', 'really', 'sorry', 'smile', 'reading', 'question', 'answer', 'session', 'count', 'thing']\n",
            "['975,\"hi', 'goyal', 'think', 'answer', 'looking', 'logical', 'would', 'participate', 'increase', 'chance', 'smile', 'community', 'initiative', 'announce', 'suppose', 'initiative', 'qualify', 'round', 'given', 'number', 'working', 'professional', 'would', 'tedious', 'participant']\n",
            "['1131,use', 'google', 'colab', 'floyd', 'cloud', 'computing', 'windows', 'better', 'cloud', 'azure', 'google', 'expensive']\n",
            "['1221,yes', 'study', 'group', 'program', 'smile', 'going', 'student', 'mentor', 'buddy', 'program', 'people', 'mentor', 'someone', 'match', 'pair']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7By9pi4wKOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dc7b5265-9097-4c2d-fd6c-c29667c3449e"
      },
      "source": [
        "# create a dictionary from the data\n",
        "# convert to bag-of-words corpus\n",
        "# save the dictionary and corpus for future use.\n",
        "\n",
        "dictionary = corpora.Dictionary(text_data)\n",
        "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
        "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
        "dictionary.save('dictionary.gensim')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBXM5ABkwNj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e4fa32ee-25d9-481f-b7f5-af9bc9add142"
      },
      "source": [
        "NUM_TOPICS = 5\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "ldamodel.save('model5.gensim')\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.043*\"student\" + 0.030*\"scholarship\" + 0.030*\"challenge\" + 0.030*\"outcome\"')\n",
            "(1, '0.034*\"answer\" + 0.026*\"question\" + 0.018*\"slack\" + 0.018*\"participation\"')\n",
            "(2, '0.024*\"would\" + 0.024*\"sorry\" + 0.024*\"account\" + 0.024*\"phase\"')\n",
            "(3, '0.047*\"count\" + 0.024*\"group\" + 0.024*\"really\" + 0.024*\"participation\"')\n",
            "(4, '0.037*\"course\" + 0.028*\"smile\" + 0.019*\"slack\" + 0.019*\"initiative\"')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L42BVl5r6iNy",
        "colab_type": "text"
      },
      "source": [
        "# Method #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOT0CPLe6kKT",
        "colab_type": "text"
      },
      "source": [
        "# Method #3"
      ]
    }
  ]
}